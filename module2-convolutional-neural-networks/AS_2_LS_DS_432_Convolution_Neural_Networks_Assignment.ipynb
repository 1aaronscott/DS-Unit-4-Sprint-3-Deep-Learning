{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "AS-2_LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDG_ZQdIqB7E",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "Load a pretrained network from Keras, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "ResNet50 = ResNet50(weights='imagenet')\n",
        "features = model.predict(x)\n",
        "\n",
        "```\n",
        "\n",
        "Next you will need to remove the last layer from the ResNet model. Here, we loop over the layers to use the sequential API. There are easier ways to add and remove layers using the Keras functional API, but doing so introduces other complexities. \n",
        "\n",
        "```python\n",
        "# Remote the Last Layer of ResNEt\n",
        "ResNet50._layers.pop(0)\n",
        "\n",
        "# Out New Model\n",
        "model = Sequential()\n",
        "\n",
        "# Add Pre-trained layers of Old Model to New Model\n",
        "for layer in ResNet50.layers:\n",
        "    model.add(layer)\n",
        "\n",
        "# Turn off additional training of ResNet Layers for speed of assignment\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add New Output Layer to Model\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "```\n",
        "\n",
        "Your assignment is to apply the transfer learning above to classify images of Mountains (`./data/mountain/*`) and images of forests (`./data/forest/*`). Treat mountains as the postive class (1) and the forest images as the negative (zero). \n",
        "\n",
        "Steps to complete assignment: \n",
        "1. Load in Image Data into numpy arrays (`X`) \n",
        "2. Create a `y` for the labels\n",
        "3. Train your model with pretrained layers from resnet\n",
        "4. Report your model's accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNUOl4S9qB7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOUR CODE HERE\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "# from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtjj6Mkwu9j1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/1aaronscott/DS-Unit-4-Sprint-3-Deep-Learning/blob/mychanges/module2-convolutional-neural-networks/data.tgz?raw=true -O data.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhLUP7R2u9mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xzf data.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSP6MpKQu9pP",
        "colab_type": "code",
        "outputId": "3b8a25eb-e7c4-4401-cfd1-d5b05beda718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "DATADIR = 'data'\n",
        "CATEGORIES = ['forest', 'mountain']\n",
        "training_data = []\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATADIR, category) # path to cats or dogs dir\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                if not img.startswith(\".jpg\"):\n",
        "                    img_array = cv2.imread(os.path.join(path, img))\n",
        "                    new_img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                    training_data.append([new_img_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for features, label in training_data:\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = to_categorical(np.array(y))\n",
        "\n",
        "    print('------- Shape of X, y data -------')\n",
        "    print(X.shape, y.shape)\n",
        "\n",
        "    return X/255.0, y #normalize the data\n",
        "X, y = create_training_data()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------- Shape of X, y data -------\n",
            "(702, 224, 224, 3) (702, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkUzmFO3u9sR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c34080c5-0f7b-4c78-c605-06b27fabd7df"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((561, 224, 224, 3), (141, 224, 224, 3), (561, 2), (141, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_NGjDkSu9vB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15, 10))\n",
        "columns = 3\n",
        "rows = 2\n",
        "for i in range(1, columns*rows +1):\n",
        "    ax = fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow((X_train[i]* 255).astype(np.uint8))\n",
        "    ax.set_xlabel(y[np.argmax(y_train[i])])\n",
        "plt.show();\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9WfQpdxu9xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "res = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "# make all resnet layers untrainable\n",
        "for layer in res.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# add your head on top\n",
        "x = res.output\n",
        "x = MaxPooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=res.input, outputs=predictions)\n",
        "\n",
        "# x = res.output\n",
        "# predictions = Dense(1, activation='sigmoid')(x)\n",
        "# model = Model(res.input, predictions)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqYJREdo_Fuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "res = ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "# make all resnet layers untrainable\n",
        "for layer in res.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# add your head on top\n",
        "x = res.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.25)(x)\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=res.input, outputs=predictions)\n",
        "\n",
        "# x = res.output\n",
        "# predictions = Dense(1, activation='sigmoid')(x)\n",
        "# model = Model(res.input, predictions)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv2djRvdu90g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9171d54-50e6-46db-f9d5-91623f01597b"
      },
      "source": [
        "%%time\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 106 ms, sys: 1.01 ms, total: 107 ms\n",
            "Wall time: 109 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErfYDOo-u93I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c6ac6554-dea8-4e88-eee1-0647f2b45637"
      },
      "source": [
        "%%time\n",
        "\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=EPOCHS, validation_split=0.2, batch_size=BATCH_SIZE, verbose=1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 448 samples, validate on 113 samples\n",
            "Epoch 1/5\n",
            "448/448 [==============================] - 148s 331ms/sample - loss: 0.5017 - acc: 0.8638 - val_loss: 0.6945 - val_acc: 0.4779\n",
            "Epoch 2/5\n",
            "448/448 [==============================] - 141s 315ms/sample - loss: 0.3199 - acc: 0.9241 - val_loss: 1.4465 - val_acc: 0.4956\n",
            "Epoch 3/5\n",
            "448/448 [==============================] - 142s 316ms/sample - loss: 0.2745 - acc: 0.9442 - val_loss: 0.9631 - val_acc: 0.4956\n",
            "Epoch 4/5\n",
            "448/448 [==============================] - 142s 316ms/sample - loss: 0.1320 - acc: 0.9531 - val_loss: 0.9444 - val_acc: 0.4956\n",
            "Epoch 5/5\n",
            "448/448 [==============================] - 142s 318ms/sample - loss: 0.0744 - acc: 0.9732 - val_loss: 1.1222 - val_acc: 0.4956\n",
            "CPU times: user 23min 11s, sys: 15.8 s, total: 23min 27s\n",
            "Wall time: 12min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI4blBKz_Fxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62723824-5004-49df-e072-564a5bf7a0e0"
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_tnBO9O_F0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e5d3d18-8f0a-4686-af86-e202f432a90a"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "141/141 - 29s - loss: 0.9282 - acc: 0.5887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwGfIzMG_F2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwsHAMlv_F5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pny4-Rw8_F8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "# Resources and Stretch Goals\n",
        "\n",
        "Stretch goals\n",
        "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
        "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
        "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
        "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
        "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
        "\n",
        "Resources\n",
        "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
        "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
        "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
        "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
        "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
      ]
    }
  ]
}